{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup and Merges\n",
    "\n",
    "This notebook takes the data, cleans it, compiles it into the datasets we need for our analysis, and saves them in this project's datafolder\n",
    "\n",
    "There are 4 datasets:\n",
    "- Orders (9994 rows)\n",
    "- Order Process Data (5899 rows)\n",
    "- Campaign Data (333 rows)\n",
    "- InternData Study (204 rows)\n",
    "\n",
    "And four events for which we have data:\n",
    "1. Order date\n",
    "2. Ready for shipping\n",
    "3. On Truck Scan\n",
    "4. Arrival Scan\n",
    "\n",
    "This gives us 3 consecutive timespans, as well as the general leadtime.\n",
    "\n",
    "We will perform the following merges to cover these timespans:\n",
    "\n",
    "- Leadtime (order date --> arrival scan): Orders merged with Campaign Data\n",
    "\n",
    "- Warehouse (order date --> ready to ship): Orders merged with Intern Data\n",
    "\n",
    "- Pickuptime (ready to ship --> Pickup/on truck): The InternData set has both ready to ship and pick up dates\n",
    "\n",
    "- Delivery (pickup/on truck --> arrival scan): Order Process merged with Campaign Data\n",
    "\n",
    "\n",
    "As the inital EDA revealed surprising behaviour of orders for which the shipmode is \"Express\", we add the shipmode-column to each dataframe we're working with.\n",
    "\n",
    "\n",
    "## Clean up\n",
    "\n",
    "The cleanup is done with one function (see below). We are only missing 11 postal codes from df_orders. This doesn't interfere with the following analysis, so we ignore them.\n",
    "The function performs the following:\n",
    "\n",
    "1. Lowercasing column names\n",
    "2. Replacing spaces in column names with underscores\n",
    "3. Checking and printing the number of duplicate rows\n",
    "4. Dropping duplicate rows\n",
    "5. Printing the number of missing values per column\n",
    "6. Returning a summary of the DataFrame after cleanup\n",
    "\n",
    "## Merges\n",
    "\n",
    "All datasets feature a column of order_id, but the dataframe's rows correspond to items, not orders. If an order comprises more than one type of item, there will be multiple rows per order_id. As we only care for the timeline, not the order's contents, for now we proceed with keeping only one row per order_id.\n",
    "\n",
    "However, as the datasets vary in size, the only robust timespan is between *order date* and *on-truck scan*. Both *ready for shipping* and *arrival scan* are part of datasets with ~200 and ~300 rows, respectively, and any combination with other events, such as order date to arrival scan will be bottlenecked by the smaller dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXTRACT:\n",
    "\n",
    "df_orders = pd.read_excel(\"data/muesli_project_raw_data.xlsx\", header=1, sheet_name=\"Orders\")\n",
    "df_order_process_data = pd.read_excel(\"data/muesli_project_raw_data.xlsx\", header=0, sheet_name=\"Order Process Data\")\n",
    "df_campaign_data = pd.read_excel(\"data/muesli_project_raw_data.xlsx\", header=0, sheet_name=\"Campaign Data\")\n",
    "df_intern_data_study = pd.read_excel(\"data/muesli_project_raw_data.xlsx\", header=0, sheet_name=\"InternData Study\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Origin Channel</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Region</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>CA-2019-121755</td>\n",
       "      <td>2019-01-16</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>EH-13945</td>\n",
       "      <td>Eric Hoffmann</td>\n",
       "      <td>Email</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>90049.0</td>\n",
       "      <td>West</td>\n",
       "      <td>Special Projects Muesil</td>\n",
       "      <td>Gluten Free</td>\n",
       "      <td>TEC-AC-10003027</td>\n",
       "      <td>90.57</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.7741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>CA-2019-118255</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>First Class</td>\n",
       "      <td>ON-18715</td>\n",
       "      <td>Odella Nelson</td>\n",
       "      <td>Sales</td>\n",
       "      <td>United States</td>\n",
       "      <td>Eagan</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55122.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>Special Projects Muesil</td>\n",
       "      <td>Gluten Free</td>\n",
       "      <td>TEC-AC-10000171</td>\n",
       "      <td>45.98</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.7714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>CA-2019-169194</td>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>LH-16900</td>\n",
       "      <td>Lena Hernandez</td>\n",
       "      <td>Email</td>\n",
       "      <td>United States</td>\n",
       "      <td>Dover</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>19901.0</td>\n",
       "      <td>East</td>\n",
       "      <td>Special Projects Muesil</td>\n",
       "      <td>Gluten Free</td>\n",
       "      <td>TEC-AC-10002167</td>\n",
       "      <td>45.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>CA-2019-111682</td>\n",
       "      <td>2019-06-17</td>\n",
       "      <td>First Class</td>\n",
       "      <td>TB-21055</td>\n",
       "      <td>Ted Butterfield</td>\n",
       "      <td>Email</td>\n",
       "      <td>United States</td>\n",
       "      <td>Troy</td>\n",
       "      <td>New York</td>\n",
       "      <td>12180.0</td>\n",
       "      <td>East</td>\n",
       "      <td>Special Projects Muesil</td>\n",
       "      <td>Gluten Free</td>\n",
       "      <td>TEC-AC-10002167</td>\n",
       "      <td>30.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>CA-2018-135545</td>\n",
       "      <td>2018-11-24</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>KM-16720</td>\n",
       "      <td>Kunst Miller</td>\n",
       "      <td>Email</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>90004.0</td>\n",
       "      <td>West</td>\n",
       "      <td>Special Projects Muesil</td>\n",
       "      <td>Gluten Free</td>\n",
       "      <td>TEC-AC-10004633</td>\n",
       "      <td>13.98</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index        Order ID Order Date       Ship Mode Customer ID  \\\n",
       "0     27  CA-2019-121755 2019-01-16    Second Class    EH-13945   \n",
       "1     45  CA-2019-118255 2019-03-11     First Class    ON-18715   \n",
       "2     48  CA-2019-169194 2019-06-20  Standard Class    LH-16900   \n",
       "3     60  CA-2019-111682 2019-06-17     First Class    TB-21055   \n",
       "4     63  CA-2018-135545 2018-11-24  Standard Class    KM-16720   \n",
       "\n",
       "     Customer Name Origin Channel Country/Region         City       State  \\\n",
       "0    Eric Hoffmann          Email  United States  Los Angeles  California   \n",
       "1    Odella Nelson          Sales  United States        Eagan   Minnesota   \n",
       "2   Lena Hernandez          Email  United States        Dover    Delaware   \n",
       "3  Ted Butterfield          Email  United States         Troy    New York   \n",
       "4     Kunst Miller          Email  United States  Los Angeles  California   \n",
       "\n",
       "   Postal Code   Region                 Category Sub-Category  \\\n",
       "0      90049.0     West  Special Projects Muesil  Gluten Free   \n",
       "1      55122.0  Central  Special Projects Muesil  Gluten Free   \n",
       "2      19901.0     East  Special Projects Muesil  Gluten Free   \n",
       "3      12180.0     East  Special Projects Muesil  Gluten Free   \n",
       "4      90004.0     West  Special Projects Muesil  Gluten Free   \n",
       "\n",
       "        Product ID  Sales  Quantity  Discount   Profit  \n",
       "0  TEC-AC-10003027  90.57         3       0.0  11.7741  \n",
       "1  TEC-AC-10000171  45.98         2       0.0  19.7714  \n",
       "2  TEC-AC-10002167  45.00         3       0.0   4.9500  \n",
       "3  TEC-AC-10002167  30.00         2       0.0   3.3000  \n",
       "4  TEC-AC-10004633  13.98         2       0.0   6.1512  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Taking a first look\n",
    "\n",
    "df_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRANSFORM\n",
    "\n",
    "## Function to clean up each dataframe\n",
    "\n",
    "def cleanup(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean up the input DataFrame by:\n",
    "    1. Lowercasing column names\n",
    "    2. Replacing spaces in column names with underscores\n",
    "    3. Checking and printing the number of duplicate rows\n",
    "    4. Dropping duplicate rows\n",
    "    5. Printing the number of missing values per column\n",
    "    6. Returning a summary of the DataFrame after cleanup\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The DataFrame to clean up.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Clean column names: lowercase and underscore instead of spaces\n",
    "    data.columns = (data.columns.str.lower()\n",
    "                    .str.replace(\" \", \"_\"))\n",
    "    \n",
    "    # Step 2: Handle duplicates\n",
    "    duplicate_rows = data[data.duplicated()]\n",
    "    print(f\"There are {len(duplicate_rows)} duplicate rows.\")\n",
    "    \n",
    "    # Drop duplicates\n",
    "    data.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    \n",
    "    # Step 3: Check for NaN values\n",
    "    missing_values = data.isna().sum()\n",
    "    print(f\"Missing values per column:\\n{missing_values}\")\n",
    "    \n",
    "    # Step 4: Return cleaned data and additional info\n",
    "    print(f\"Summary after cleanup:\\n\")\n",
    "    data_info = data.info()  \n",
    "    \n",
    "    \n",
    "    return data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicate rows.\n",
      "Missing values per column:\n",
      "index              0\n",
      "order_id           0\n",
      "order_date         0\n",
      "ship_mode          0\n",
      "customer_id        0\n",
      "customer_name      0\n",
      "origin_channel     0\n",
      "country/region     0\n",
      "city               0\n",
      "state              0\n",
      "postal_code       11\n",
      "region             0\n",
      "category           0\n",
      "sub-category       0\n",
      "product_id         0\n",
      "sales              0\n",
      "quantity           0\n",
      "discount           0\n",
      "profit             0\n",
      "dtype: int64\n",
      "Summary after cleanup:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9994 entries, 0 to 9993\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   index           9994 non-null   int64         \n",
      " 1   order_id        9994 non-null   object        \n",
      " 2   order_date      9994 non-null   datetime64[ns]\n",
      " 3   ship_mode       9994 non-null   object        \n",
      " 4   customer_id     9994 non-null   object        \n",
      " 5   customer_name   9994 non-null   object        \n",
      " 6   origin_channel  9994 non-null   object        \n",
      " 7   country/region  9994 non-null   object        \n",
      " 8   city            9994 non-null   object        \n",
      " 9   state           9994 non-null   object        \n",
      " 10  postal_code     9983 non-null   float64       \n",
      " 11  region          9994 non-null   object        \n",
      " 12  category        9994 non-null   object        \n",
      " 13  sub-category    9994 non-null   object        \n",
      " 14  product_id      9994 non-null   object        \n",
      " 15  sales           9994 non-null   float64       \n",
      " 16  quantity        9994 non-null   int64         \n",
      " 17  discount        9994 non-null   float64       \n",
      " 18  profit          9994 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(2), object(12)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>ship_mode</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>origin_channel</th>\n",
       "      <th>country/region</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>region</th>\n",
       "      <th>category</th>\n",
       "      <th>sub-category</th>\n",
       "      <th>product_id</th>\n",
       "      <th>sales</th>\n",
       "      <th>quantity</th>\n",
       "      <th>discount</th>\n",
       "      <th>profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>CA-2019-121755</td>\n",
       "      <td>2019-01-16</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>EH-13945</td>\n",
       "      <td>Eric Hoffmann</td>\n",
       "      <td>Email</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>90049.0</td>\n",
       "      <td>West</td>\n",
       "      <td>Special Projects Muesil</td>\n",
       "      <td>Gluten Free</td>\n",
       "      <td>TEC-AC-10003027</td>\n",
       "      <td>90.570</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.7741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>CA-2019-118255</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>First Class</td>\n",
       "      <td>ON-18715</td>\n",
       "      <td>Odella Nelson</td>\n",
       "      <td>Sales</td>\n",
       "      <td>United States</td>\n",
       "      <td>Eagan</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>55122.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>Special Projects Muesil</td>\n",
       "      <td>Gluten Free</td>\n",
       "      <td>TEC-AC-10000171</td>\n",
       "      <td>45.980</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.7714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>CA-2019-169194</td>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>LH-16900</td>\n",
       "      <td>Lena Hernandez</td>\n",
       "      <td>Email</td>\n",
       "      <td>United States</td>\n",
       "      <td>Dover</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>19901.0</td>\n",
       "      <td>East</td>\n",
       "      <td>Special Projects Muesil</td>\n",
       "      <td>Gluten Free</td>\n",
       "      <td>TEC-AC-10002167</td>\n",
       "      <td>45.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>CA-2019-111682</td>\n",
       "      <td>2019-06-17</td>\n",
       "      <td>First Class</td>\n",
       "      <td>TB-21055</td>\n",
       "      <td>Ted Butterfield</td>\n",
       "      <td>Email</td>\n",
       "      <td>United States</td>\n",
       "      <td>Troy</td>\n",
       "      <td>New York</td>\n",
       "      <td>12180.0</td>\n",
       "      <td>East</td>\n",
       "      <td>Special Projects Muesil</td>\n",
       "      <td>Gluten Free</td>\n",
       "      <td>TEC-AC-10002167</td>\n",
       "      <td>30.000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>CA-2018-135545</td>\n",
       "      <td>2018-11-24</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>KM-16720</td>\n",
       "      <td>Kunst Miller</td>\n",
       "      <td>Email</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>90004.0</td>\n",
       "      <td>West</td>\n",
       "      <td>Special Projects Muesil</td>\n",
       "      <td>Gluten Free</td>\n",
       "      <td>TEC-AC-10004633</td>\n",
       "      <td>13.980</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>9894</td>\n",
       "      <td>US-2019-115441</td>\n",
       "      <td>2019-07-25</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>SH-19975</td>\n",
       "      <td>Sally Hughsby</td>\n",
       "      <td>Sales</td>\n",
       "      <td>United States</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>53209.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>Toasted Muesli</td>\n",
       "      <td>With Nuts</td>\n",
       "      <td>FUR-CH-10004626</td>\n",
       "      <td>403.560</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.8544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>9908</td>\n",
       "      <td>US-2018-129007</td>\n",
       "      <td>2018-09-13</td>\n",
       "      <td>First Class</td>\n",
       "      <td>KD-16615</td>\n",
       "      <td>Ken Dana</td>\n",
       "      <td>Sales</td>\n",
       "      <td>United States</td>\n",
       "      <td>Anaheim</td>\n",
       "      <td>California</td>\n",
       "      <td>92804.0</td>\n",
       "      <td>West</td>\n",
       "      <td>Toasted Muesli</td>\n",
       "      <td>With Nuts</td>\n",
       "      <td>FUR-CH-10000155</td>\n",
       "      <td>717.720</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>71.7720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>9913</td>\n",
       "      <td>CA-2018-132388</td>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>First Class</td>\n",
       "      <td>KN-16390</td>\n",
       "      <td>Katherine Nockton</td>\n",
       "      <td>Sales</td>\n",
       "      <td>United States</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>California</td>\n",
       "      <td>93101.0</td>\n",
       "      <td>West</td>\n",
       "      <td>Toasted Muesli</td>\n",
       "      <td>With Nuts</td>\n",
       "      <td>FUR-CH-10001714</td>\n",
       "      <td>362.136</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-54.3204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>9920</td>\n",
       "      <td>CA-2019-149272</td>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>MY-18295</td>\n",
       "      <td>Muhammed Yedwab</td>\n",
       "      <td>Sales</td>\n",
       "      <td>United States</td>\n",
       "      <td>Bryan</td>\n",
       "      <td>Texas</td>\n",
       "      <td>77803.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>Toasted Muesli</td>\n",
       "      <td>With Nuts</td>\n",
       "      <td>FUR-CH-10000863</td>\n",
       "      <td>528.430</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-143.4310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>9948</td>\n",
       "      <td>CA-2020-121559</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>HW-14935</td>\n",
       "      <td>Helen Wasserman</td>\n",
       "      <td>Sales</td>\n",
       "      <td>United States</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>46203.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>Toasted Muesli</td>\n",
       "      <td>With Nuts</td>\n",
       "      <td>FUR-CH-10003746</td>\n",
       "      <td>1925.880</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>539.2464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9994 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index        order_id order_date       ship_mode customer_id  \\\n",
       "0        27  CA-2019-121755 2019-01-16    Second Class    EH-13945   \n",
       "1        45  CA-2019-118255 2019-03-11     First Class    ON-18715   \n",
       "2        48  CA-2019-169194 2019-06-20  Standard Class    LH-16900   \n",
       "3        60  CA-2019-111682 2019-06-17     First Class    TB-21055   \n",
       "4        63  CA-2018-135545 2018-11-24  Standard Class    KM-16720   \n",
       "...     ...             ...        ...             ...         ...   \n",
       "9989   9894  US-2019-115441 2019-07-25    Second Class    SH-19975   \n",
       "9990   9908  US-2018-129007 2018-09-13     First Class    KD-16615   \n",
       "9991   9913  CA-2018-132388 2018-10-10     First Class    KN-16390   \n",
       "9992   9920  CA-2019-149272 2019-03-15  Standard Class    MY-18295   \n",
       "9993   9948  CA-2020-121559 2020-06-01    Second Class    HW-14935   \n",
       "\n",
       "          customer_name origin_channel country/region           city  \\\n",
       "0         Eric Hoffmann          Email  United States    Los Angeles   \n",
       "1         Odella Nelson          Sales  United States          Eagan   \n",
       "2        Lena Hernandez          Email  United States          Dover   \n",
       "3       Ted Butterfield          Email  United States           Troy   \n",
       "4          Kunst Miller          Email  United States    Los Angeles   \n",
       "...                 ...            ...            ...            ...   \n",
       "9989      Sally Hughsby          Sales  United States      Milwaukee   \n",
       "9990           Ken Dana          Sales  United States        Anaheim   \n",
       "9991  Katherine Nockton          Sales  United States  Santa Barbara   \n",
       "9992    Muhammed Yedwab          Sales  United States          Bryan   \n",
       "9993    Helen Wasserman          Sales  United States   Indianapolis   \n",
       "\n",
       "           state  postal_code   region                 category sub-category  \\\n",
       "0     California      90049.0     West  Special Projects Muesil  Gluten Free   \n",
       "1      Minnesota      55122.0  Central  Special Projects Muesil  Gluten Free   \n",
       "2       Delaware      19901.0     East  Special Projects Muesil  Gluten Free   \n",
       "3       New York      12180.0     East  Special Projects Muesil  Gluten Free   \n",
       "4     California      90004.0     West  Special Projects Muesil  Gluten Free   \n",
       "...          ...          ...      ...                      ...          ...   \n",
       "9989   Wisconsin      53209.0  Central           Toasted Muesli    With Nuts   \n",
       "9990  California      92804.0     West           Toasted Muesli    With Nuts   \n",
       "9991  California      93101.0     West           Toasted Muesli    With Nuts   \n",
       "9992       Texas      77803.0  Central           Toasted Muesli    With Nuts   \n",
       "9993     Indiana      46203.0  Central           Toasted Muesli    With Nuts   \n",
       "\n",
       "           product_id     sales  quantity  discount    profit  \n",
       "0     TEC-AC-10003027    90.570         3       0.0   11.7741  \n",
       "1     TEC-AC-10000171    45.980         2       0.0   19.7714  \n",
       "2     TEC-AC-10002167    45.000         3       0.0    4.9500  \n",
       "3     TEC-AC-10002167    30.000         2       0.0    3.3000  \n",
       "4     TEC-AC-10004633    13.980         2       0.0    6.1512  \n",
       "...               ...       ...       ...       ...       ...  \n",
       "9989  FUR-CH-10004626   403.560         4       0.0   96.8544  \n",
       "9990  FUR-CH-10000155   717.720         3       0.2   71.7720  \n",
       "9991  FUR-CH-10001714   362.136         3       0.2  -54.3204  \n",
       "9992  FUR-CH-10000863   528.430         5       0.3 -143.4310  \n",
       "9993  FUR-CH-10003746  1925.880         6       0.0  539.2464  \n",
       "\n",
       "[9994 rows x 19 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanup(df_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicate rows.\n",
      "Missing values per column:\n",
      "row_id                0\n",
      "order_id              0\n",
      "order_date            0\n",
      "on_truck_scan_date    0\n",
      "ship_mode             0\n",
      "dtype: int64\n",
      "Summary after cleanup:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5899 entries, 0 to 5898\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   row_id              5899 non-null   int64         \n",
      " 1   order_id            5899 non-null   object        \n",
      " 2   order_date          5899 non-null   datetime64[ns]\n",
      " 3   on_truck_scan_date  5899 non-null   datetime64[ns]\n",
      " 4   ship_mode           5899 non-null   object        \n",
      "dtypes: datetime64[ns](2), int64(1), object(2)\n",
      "memory usage: 230.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>on_truck_scan_date</th>\n",
       "      <th>ship_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3074</td>\n",
       "      <td>CA-2019-125206</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>Express</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4919</td>\n",
       "      <td>CA-2019-160304</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>Standard Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4920</td>\n",
       "      <td>CA-2019-160304</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>Standard Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8604</td>\n",
       "      <td>US-2019-116365</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>Standard Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8605</td>\n",
       "      <td>US-2019-116365</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>Standard Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5894</th>\n",
       "      <td>908</td>\n",
       "      <td>CA-2020-143259</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>Standard Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5895</th>\n",
       "      <td>909</td>\n",
       "      <td>CA-2020-143259</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>Standard Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5896</th>\n",
       "      <td>1297</td>\n",
       "      <td>CA-2020-115427</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>Standard Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5897</th>\n",
       "      <td>1298</td>\n",
       "      <td>CA-2020-115427</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>Standard Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5898</th>\n",
       "      <td>5092</td>\n",
       "      <td>CA-2020-156720</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>Standard Processing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5899 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id        order_id order_date on_truck_scan_date  \\\n",
       "0       3074  CA-2019-125206 2019-01-03         2019-01-07   \n",
       "1       4919  CA-2019-160304 2019-01-02         2019-01-09   \n",
       "2       4920  CA-2019-160304 2019-01-02         2019-01-09   \n",
       "3       8604  US-2019-116365 2019-01-03         2019-01-09   \n",
       "4       8605  US-2019-116365 2019-01-03         2019-01-09   \n",
       "...      ...             ...        ...                ...   \n",
       "5894     908  CA-2020-143259 2020-12-30         2021-01-06   \n",
       "5895     909  CA-2020-143259 2020-12-30         2021-01-06   \n",
       "5896    1297  CA-2020-115427 2020-12-30         2021-01-06   \n",
       "5897    1298  CA-2020-115427 2020-12-30         2021-01-06   \n",
       "5898    5092  CA-2020-156720 2020-12-30         2021-01-06   \n",
       "\n",
       "                ship_mode  \n",
       "0                 Express  \n",
       "1     Standard Processing  \n",
       "2     Standard Processing  \n",
       "3     Standard Processing  \n",
       "4     Standard Processing  \n",
       "...                   ...  \n",
       "5894  Standard Processing  \n",
       "5895  Standard Processing  \n",
       "5896  Standard Processing  \n",
       "5897  Standard Processing  \n",
       "5898  Standard Processing  \n",
       "\n",
       "[5899 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanup(df_order_process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicate rows.\n",
      "Missing values per column:\n",
      "order_id             0\n",
      "arrival_scan_date    0\n",
      "customer_name        0\n",
      "dtype: int64\n",
      "Summary after cleanup:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 333 entries, 0 to 332\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   order_id           333 non-null    object        \n",
      " 1   arrival_scan_date  333 non-null    datetime64[ns]\n",
      " 2   customer_name      333 non-null    object        \n",
      "dtypes: datetime64[ns](1), object(2)\n",
      "memory usage: 7.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>arrival_scan_date</th>\n",
       "      <th>customer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA-2019-109666</td>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>Kunst Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA-2019-138933</td>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>Jack Lebron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA-2019-130001</td>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>Heather Kirkland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA-2019-113061</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>Ed Ludwig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA-2019-162138</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>Grace Kelly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>CA-2020-129707</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>Larry Hughes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>CA-2020-125381</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>Speros Goranitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>CA-2020-141733</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>Rick Wilson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>US-2020-104451</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>Michelle Moray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>US-2020-139647</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>Todd Sumrall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           order_id arrival_scan_date     customer_name\n",
       "0    CA-2019-109666        2019-05-03      Kunst Miller\n",
       "1    CA-2019-138933        2019-05-03       Jack Lebron\n",
       "2    CA-2019-130001        2019-05-03  Heather Kirkland\n",
       "3    CA-2019-113061        2019-05-06         Ed Ludwig\n",
       "4    CA-2019-162138        2019-05-06       Grace Kelly\n",
       "..              ...               ...               ...\n",
       "328  CA-2020-129707        2020-05-08      Larry Hughes\n",
       "329  CA-2020-125381        2020-05-08  Speros Goranitis\n",
       "330  CA-2020-141733        2020-05-15       Rick Wilson\n",
       "331  US-2020-104451        2020-05-15    Michelle Moray\n",
       "332  US-2020-139647        2020-05-15      Todd Sumrall\n",
       "\n",
       "[333 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanup(df_campaign_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 86 duplicate rows.\n",
      "Missing values per column:\n",
      "order_id              0\n",
      "ready_to_ship_date    0\n",
      "pickup_date           0\n",
      "dtype: int64\n",
      "Summary after cleanup:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 204 entries, 0 to 203\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   order_id            204 non-null    object        \n",
      " 1   ready_to_ship_date  204 non-null    datetime64[ns]\n",
      " 2   pickup_date         204 non-null    datetime64[ns]\n",
      "dtypes: datetime64[ns](2), object(1)\n",
      "memory usage: 4.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>ready_to_ship_date</th>\n",
       "      <th>pickup_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA-2019-116540</td>\n",
       "      <td>2019-09-02</td>\n",
       "      <td>2019-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA-2019-129847</td>\n",
       "      <td>2019-09-04</td>\n",
       "      <td>2019-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA-2019-129630</td>\n",
       "      <td>2019-09-04</td>\n",
       "      <td>2019-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA-2019-106278</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>2019-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA-2019-158099</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>2019-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>US-2020-165456</td>\n",
       "      <td>2020-12-03</td>\n",
       "      <td>2020-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>US-2020-110576</td>\n",
       "      <td>2020-12-04</td>\n",
       "      <td>2020-12-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>CA-2020-105333</td>\n",
       "      <td>2020-12-04</td>\n",
       "      <td>2020-12-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>CA-2020-119305</td>\n",
       "      <td>2020-12-04</td>\n",
       "      <td>2020-12-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>CA-2020-142090</td>\n",
       "      <td>2020-12-07</td>\n",
       "      <td>2020-12-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           order_id ready_to_ship_date pickup_date\n",
       "0    CA-2019-116540         2019-09-02  2019-09-03\n",
       "1    CA-2019-129847         2019-09-04  2019-09-04\n",
       "2    CA-2019-129630         2019-09-04  2019-09-04\n",
       "3    CA-2019-106278         2019-09-05  2019-09-06\n",
       "4    CA-2019-158099         2019-09-05  2019-09-06\n",
       "..              ...                ...         ...\n",
       "199  US-2020-165456         2020-12-03  2020-12-04\n",
       "200  US-2020-110576         2020-12-04  2020-12-07\n",
       "201  CA-2020-105333         2020-12-04  2020-12-07\n",
       "202  CA-2020-119305         2020-12-04  2020-12-07\n",
       "203  CA-2020-142090         2020-12-07  2020-12-09\n",
       "\n",
       "[204 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanup(df_intern_data_study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Merges: Unique order_id's\n",
    "\n",
    "In order to merge on each dataset's order_id, we want to make sure that each dataset has unique order_id's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orders needs to be fixed\n",
      "order_process needs to be fixed\n",
      "intern is good\n",
      "campaign is good\n"
     ]
    }
   ],
   "source": [
    "print(\"orders needs to be fixed\") if df_orders[\"order_id\"].nunique() != len(df_orders) else print(\"orders are good\")\n",
    "\n",
    "print(\"order_process needs to be fixed\") if df_order_process_data[\"order_id\"].nunique() != len(df_order_process_data) else print(\"order_process is good\")\n",
    "\n",
    "print(\"intern needs to be fixed\") if df_intern_data_study[\"order_id\"].nunique() != len(df_intern_data_study) else print(\"intern is good\")\n",
    "\n",
    "print(\"campaign needs to be fixed\") if df_campaign_data[\"order_id\"].nunique() != len(df_campaign_data) else print(\"campaign is good\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For df_orders: It turns out that order_id's are not unique, as each row corresponds to an item bought. If an order comprises more than one item, that order_id will appear for every type of item bought within that order. \n",
    "\n",
    "For our purposes, as we don't care for the contents of the order (for now at least), we remove duplicates of order id's. Then we merge.\n",
    "\n",
    "But first, let's doublecheck whether there is only ever one date per oder_id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: order_date, dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we group by 'order_id' and check the number of unique dates per order\n",
    "duplicate_dates = df_orders.groupby(\"order_id\")[\"order_date\"].nunique()\n",
    "\n",
    "# Our hypothesis is that there are no order_id's with more than one unique date. \n",
    "# We filter to find order_ids that have more than one unique date\n",
    "multiple_dates = duplicate_dates[duplicate_dates > 1]\n",
    "\n",
    "# Show the order_ids with multiple dates\n",
    "multiple_dates\n",
    "\n",
    "##Ergo, we can proceed with keeping only one row per order_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregation: Turn multiple rows per order_id into one row per order_id\n",
    "\n",
    "\n",
    "##we aggregate the columns with \"sum\"\n",
    "#except for the orderdate, where we display the latest (which is safe, since we have checked that there is always only one date per order_id)\n",
    "\n",
    "#in summing the amounts, we still keep the information how many items an order comprised. However, we lose the information how many types of items were bought.\n",
    "\n",
    "agg_funcs = {\n",
    "    \"order_date\": \"max\",  # Get the \"latest\" order date\n",
    "    \"sales\": \"sum\",       # Sum the amounts\n",
    "    \"quantity\": \"sum\",       # Sum the amounts\n",
    "    \"discount\": \"sum\",       # Sum the amounts\n",
    "    \"profit\": \"sum\"       # Sum the amounts\n",
    "\n",
    "}\n",
    "\n",
    "#df_orders_grouped is ready to be merged\n",
    "df_orders_grouped = df_orders.groupby(\"order_id\").agg(agg_funcs).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taking a look\n",
    "df_orders_grouped.head()\n",
    "\n",
    "## and save the clean dataset for later use:\n",
    "df_orders_grouped.to_csv(\"data/orders.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For df_order_process_data: row_id makes otherwise duplicate rows to be different, without containing relevant information. We drop it and remove duplicates by running our cleanup function again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping row_id, which causes otherwise duplicate rows to evade our cleanup-function\n",
    "df_order_process_data.drop(columns=[\"row_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2896 duplicate rows.\n",
      "Missing values per column:\n",
      "order_id              0\n",
      "order_date            0\n",
      "on_truck_scan_date    0\n",
      "ship_mode             0\n",
      "dtype: int64\n",
      "Summary after cleanup:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3003 entries, 0 to 3002\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   order_id            3003 non-null   object        \n",
      " 1   order_date          3003 non-null   datetime64[ns]\n",
      " 2   on_truck_scan_date  3003 non-null   datetime64[ns]\n",
      " 3   ship_mode           3003 non-null   object        \n",
      "dtypes: datetime64[ns](2), object(2)\n",
      "memory usage: 94.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>on_truck_scan_date</th>\n",
       "      <th>ship_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA-2019-125206</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>Express</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA-2019-160304</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>Standard Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US-2019-116365</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>Standard Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA-2019-105207</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>Standard Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA-2019-158211</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>Standard Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>CA-2020-130631</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>Standard Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>CA-2020-126221</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>Standard Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>CA-2020-143259</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>Standard Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>CA-2020-115427</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>Standard Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>CA-2020-156720</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>Standard Processing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3003 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            order_id order_date on_truck_scan_date            ship_mode\n",
       "0     CA-2019-125206 2019-01-03         2019-01-07              Express\n",
       "1     CA-2019-160304 2019-01-02         2019-01-09  Standard Processing\n",
       "2     US-2019-116365 2019-01-03         2019-01-09  Standard Processing\n",
       "3     CA-2019-105207 2019-01-03         2019-01-09  Standard Processing\n",
       "4     CA-2019-158211 2019-01-04         2019-01-09  Standard Processing\n",
       "...              ...        ...                ...                  ...\n",
       "2998  CA-2020-130631 2020-12-29         2021-01-06  Standard Processing\n",
       "2999  CA-2020-126221 2020-12-30         2021-01-06  Standard Processing\n",
       "3000  CA-2020-143259 2020-12-30         2021-01-06  Standard Processing\n",
       "3001  CA-2020-115427 2020-12-30         2021-01-06  Standard Processing\n",
       "3002  CA-2020-156720 2020-12-30         2021-01-06  Standard Processing\n",
       "\n",
       "[3003 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run the cleanup again\n",
    "cleanup(df_order_process_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check again if we fixed everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orders are good\n",
      "order_process needs to be fixed\n",
      "intern is good\n",
      "campaign is good\n"
     ]
    }
   ],
   "source": [
    "print(\"orders needs to be fixed\") if df_orders_grouped[\"order_id\"].nunique() != len(df_orders_grouped) else print(\"orders are good\")\n",
    "\n",
    "print(\"order_process needs to be fixed\") if df_order_process_data[\"order_id\"].nunique() != len(df_order_process_data) else print(\"order_process is good\")\n",
    "\n",
    "print(\"intern needs to be fixed\") if df_intern_data_study[\"order_id\"].nunique() != len(df_intern_data_study) else print(\"intern is good\")\n",
    "\n",
    "print(\"campaign needs to be fixed\") if df_campaign_data[\"order_id\"].nunique() != len(df_campaign_data) else print(\"campaign is good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>on_truck_scan_date</th>\n",
       "      <th>ship_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>CA-2020-101182</td>\n",
       "      <td>2020-09-04</td>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>Express</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>CA-2020-101182</td>\n",
       "      <td>2020-09-04</td>\n",
       "      <td>2020-09-08</td>\n",
       "      <td>Express</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            order_id order_date on_truck_scan_date ship_mode\n",
       "2140  CA-2020-101182 2020-09-04         2020-09-07   Express\n",
       "2141  CA-2020-101182 2020-09-04         2020-09-08   Express"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#since there are still duplicate order_id's in order_process, let's take a closer look\n",
    "\n",
    "duplicate_orders = df_order_process_data[df_order_process_data.duplicated(subset=[\"order_id\"], keep=False)]\n",
    "duplicate_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_process is good\n"
     ]
    }
   ],
   "source": [
    "# The same order_id has been scanned twice, on two consecutive days. \n",
    "# We'll keep the earlier one, as it had to have been on a truck to be scanned on a truck, and judge the other row to be erroneous.\n",
    "\n",
    "df_order_process_data.drop(2141, inplace=True)\n",
    "\n",
    "print(\"order_process needs to be fixed\") if df_order_process_data[\"order_id\"].nunique() != len(df_order_process_data) else print(\"order_process is good\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging: Lead Time (Order --> Arrival Scan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>sales</th>\n",
       "      <th>quantity</th>\n",
       "      <th>discount</th>\n",
       "      <th>profit</th>\n",
       "      <th>arrival_scan_date</th>\n",
       "      <th>customer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA-2019-100041</td>\n",
       "      <td>2019-11-20</td>\n",
       "      <td>328.540</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157.3777</td>\n",
       "      <td>2019-12-02</td>\n",
       "      <td>Barbara Fisher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA-2019-100083</td>\n",
       "      <td>2019-11-24</td>\n",
       "      <td>24.784</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.7450</td>\n",
       "      <td>2019-12-09</td>\n",
       "      <td>Carol Darley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA-2019-100244</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>475.694</td>\n",
       "      <td>19</td>\n",
       "      <td>0.4</td>\n",
       "      <td>175.6262</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>Greg Maxwell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA-2019-100468</td>\n",
       "      <td>2019-11-24</td>\n",
       "      <td>43.460</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.4334</td>\n",
       "      <td>2019-12-09</td>\n",
       "      <td>Alyssa Tate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA-2019-100510</td>\n",
       "      <td>2019-05-12</td>\n",
       "      <td>641.980</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>307.7496</td>\n",
       "      <td>2019-05-28</td>\n",
       "      <td>Harry Marie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id order_date    sales  quantity  discount    profit  \\\n",
       "0  CA-2019-100041 2019-11-20  328.540         6       0.0  157.3777   \n",
       "1  CA-2019-100083 2019-11-24   24.784         1       0.2    7.7450   \n",
       "2  CA-2019-100244 2019-09-20  475.694        19       0.4  175.6262   \n",
       "3  CA-2019-100468 2019-11-24   43.460         4       0.2    6.4334   \n",
       "4  CA-2019-100510 2019-05-12  641.980         7       0.0  307.7496   \n",
       "\n",
       "  arrival_scan_date   customer_name  \n",
       "0        2019-12-02  Barbara Fisher  \n",
       "1        2019-12-09    Carol Darley  \n",
       "2        2019-09-30    Greg Maxwell  \n",
       "3        2019-12-09     Alyssa Tate  \n",
       "4        2019-05-28     Harry Marie  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Merging: Orders and Campaign --> This gives us the order date and arrival scan.\n",
    "#(bottlenecked by the smaller campaign set to 333 rows only)\n",
    "\n",
    "df_lead = df_orders_grouped.merge(df_campaign_data, how=\"inner\", on=\"order_id\")\n",
    "df_lead.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add shipmode to df_lead:\n",
    "df_lead = df_lead.merge(df_order_process_data[[\"order_id\", \"ship_mode\"]], on=\"order_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD: locally as csv:\n",
    "\n",
    "df_lead.to_csv(\"data/leadtime.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging: Warehouse Time (Order --> Ready to Ship)\n",
    "\n",
    "- The InternDataSet has the data for when orders are ready to ship and when they are picked up\n",
    "- OrderProcesses has a row_id column that causes otherwise duplicate rows not to be flagged as duplicates. We remove the row and run our cleanup-function again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>ready_to_ship_date</th>\n",
       "      <th>pickup_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA-2019-116540</td>\n",
       "      <td>2019-09-02</td>\n",
       "      <td>2019-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA-2019-129847</td>\n",
       "      <td>2019-09-04</td>\n",
       "      <td>2019-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA-2019-129630</td>\n",
       "      <td>2019-09-04</td>\n",
       "      <td>2019-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA-2019-106278</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>2019-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA-2019-158099</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>2019-09-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id ready_to_ship_date pickup_date\n",
       "0  CA-2019-116540         2019-09-02  2019-09-03\n",
       "1  CA-2019-129847         2019-09-04  2019-09-04\n",
       "2  CA-2019-129630         2019-09-04  2019-09-04\n",
       "3  CA-2019-106278         2019-09-05  2019-09-06\n",
       "4  CA-2019-158099         2019-09-05  2019-09-06"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_intern_data_study.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_warehouse = df_intern_data_study.merge(df_order_process_data, how=\"inner\", on=\"order_id\")\n",
    "\n",
    "#as we merge with order_process anyway, no need to add the shipmode-column. Its already there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_warehouse.to_csv(\"data/warehouse.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging: Pick up time\n",
    "\n",
    "No need, since both *ready to ship* and *pick up* are contained in the Intern Data set. Still, we add the \"ship_mode\" column to verify the assumption that express-shippings are shipped the day they are ready to ship.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add shipmode to df_intern:\n",
    "df_intern_data_study = df_intern_data_study.merge(df_order_process_data[[\"order_id\", \"ship_mode\"]], on=\"order_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intern_data_study.to_csv(\"data/pickup.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging: Delivery\n",
    "\n",
    "We'll use the OrderProcess data for *on truck scans* and the CampaignData set for the *arrival scan*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delivery = df_order_process_data.merge(df_campaign_data, how=\"inner\", on=\"order_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add shipmode to df_delivery:\n",
    "df_delivery = df_delivery.merge(df_order_process_data[[\"order_id\", \"ship_mode\"]], on=\"order_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delivery.to_csv(\"data/delivery.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The End\n",
    "\n",
    "This concludes cleaning and merging the datasets in order to perform an inital EDA in the next notebook.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
